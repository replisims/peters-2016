% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  english,
  doc,floatsintext,draftall]{apa6}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Replication Report - Peters et al.~2006},
  pdfauthor={Anna Lohmann1 \& Rolf H. H. Groenwold1,2},
  pdflang={en-EN},
  pdfkeywords={replication, replicability, simulation study, publication bias, meta-analysis, Egger's regression test, Peters' regression test},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
% Manuscript styling
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

% Table formatting
\usepackage{longtable}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\begin{center}\begin{threeparttable}}
%   {\end{threeparttable}\end{center}\end{landscape}}
\newenvironment{lltable}{\begin{landscape}\begin{center}\begin{ThreePartTable}}{\end{ThreePartTable}\end{center}\end{landscape}}

% Enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}

% \setlength{\parindent}{0.5in}
% \setlength{\parskip}{0pt plus 0pt minus 0pt}

% \usepackage{etoolbox}
\makeatletter
\patchcmd{\HyOrg@maketitle}
  {\section{\normalfont\normalsize\abstractname}}
  {\section*{\normalfont\normalsize\abstractname}}
  {}{\typeout{Failed to patch abstract.}}
\patchcmd{\HyOrg@maketitle}
  {\section{\protect\normalfont{\@title}}}
  {\section*{\protect\normalfont{\@title}}}
  {}{\typeout{Failed to patch title.}}
\makeatother
\shorttitle{Replication Report}
\keywords{replication, replicability, simulation study, publication bias, meta-analysis, Egger's regression test, Peters' regression test\newline\indent Word count: X}
\usepackage{csquotes}
\usepackage{pmboxdraw}
\usepackage{placeins}
\usepackage{enumitem}
\ifxetex
  % Load polyglossia as late as possible: uses bidi with RTL langages (e.g. Hebrew, Arabic)
  \usepackage{polyglossia}
  \setmainlanguage[]{english}
\else
  \usepackage[shorthands=off,main=english]{babel}
\fi

\title{Replication Report - Peters et al.~2006}
\author{Anna Lohmann\textsuperscript{1} \& Rolf H. H. Groenwold\textsuperscript{1,2}}
\date{}


\authornote{

Anna Lohmann, Department of Clinical Epidemiology, Leiden University Medical Center, Leiden, The Netherland.

Rolf H.H.Groenwold, Department of Clinical Epidemiology, Leiden University Medical Center, Leiden, The Netherland. Department of Biomedical Data Sciences, Leiden University Medical Center, Leiden, The Netherlands.

The authors made the following contributions. Anna Lohmann: Data Curation, Formal Analysis (lead), Investigation, Software, Visualization, Writing - Original Draft Preparation, Writing - Review \& Editing; Rolf H. H. Groenwold: Conceptualization, Formal Analysis (supporting), Funding Acquisition, Supervision, Writing - Review \& Editing.

}

\affiliation{\vspace{0.5cm}\textsuperscript{1,2} Leiden University Medical Center}

\abstract{
Some summary.
}



\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

This replication report documents the replication attempt of the simulation study Peters, J. L., Sutton, A. J., Jones, D. R., Abrams, K. R., \& Rushton, L. (2006). Comparison of Two Methods to Detect Publication Bias in Meta-analysis. \emph{JAMA}, 295(\emph{6}), 676--678. \url{https://doi.org/10.1001/jama.295.6.676} (Peters, Sutton, Jones, Abrams, \& Rushton, 2006).
Following the definition of Rougier et al. (2017) we understand the replication of a published study as writing and running new code based on the description provided in the original publication with the aim of obtaining the same results.

The methods section details the sources of information utilized for the present replication attempt. It furthermore provides an overview of the information that was extracted from these sources as well as the technical implementation of the replication.
A separate section covers all replicator degrees of freedom, i.e.~decisions that had to be made by the replicators due to of insufficient or contradicting information in the original sources.

In the results section we present descriptive statistics from the data generating mechanism, i.e.~the artificial sample.
as well as the replicated results.

The discussion section reflects the replication attempt with regards to general replicability, replicator degrees of freedom and equivalence of results.
The appendix contains the README file providing an overview of the accompanying code as well as additional results figures that do not correspond to the original manuscript.

\hypertarget{method}{%
\section{Method}\label{method}}

\hypertarget{information-basis}{%
\subsection{Information basis}\label{information-basis}}

The information upon which the replication is based stems from two different sources (1) the published manuscript (Peters et al., 2006) (referred to as \emph{\enquote{(original) article}}) as well as (2) a technical report (Peters, Sutton, Jones, Abrams, \& Rushton, 2005).
The published article is fairly brief and repeatedly refers to details obtainable from a technical report.
The technical report is listed in the reference section of the published article, however it was not available from the public domain (i.e.~online line supplements or a public online repository).
The technical report was hence requested and obtained by email from the Department of Health Sciences at Leister University (\href{mailto:hsenquiries@leicester.ac.uk}{\nolinkurl{hsenquiries@leicester.ac.uk}}).

\hypertarget{data-generating-mechanism}{%
\subsection{Data Generating Mechanism}\label{data-generating-mechanism}}

Information provided in the above mentioned sources indicated that the following simulation factors were systematically varied in generating the artificial data.

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.37\columnwidth}\raggedright
Simulation factor\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\raggedright
No.~levels\strut
\end{minipage} & \begin{minipage}[b]{0.43\columnwidth}\raggedright
Levels\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.37\columnwidth}\raggedright
\emph{Varied}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.43\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.37\columnwidth}\raggedright
Publication bias\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
5\strut
\end{minipage} & \begin{minipage}[t]{0.43\columnwidth}\raggedright
none, effect size based moderate (14\%), effect size based severe (40\%), p-value based moderate, p-value based severe\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.37\columnwidth}\raggedright
True effect size (OR)\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
5\strut
\end{minipage} & \begin{minipage}[t]{0.43\columnwidth}\raggedright
1, 1.2, 1.5, 3, 5\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.37\columnwidth}\raggedright
Between Study Heterogeneity (\(I^2\))\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
4\strut
\end{minipage} & \begin{minipage}[t]{0.43\columnwidth}\raggedright
0, 20, 150, 500 (0, 16.7\%, 60\%, 83.3\%)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.37\columnwidth}\raggedright
Number of primary studies in meta-analysis\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
4\strut
\end{minipage} & \begin{minipage}[t]{0.43\columnwidth}\raggedright
6, 16, 30, 90\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.37\columnwidth}\raggedright
\emph{Fixed}\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.43\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.37\columnwidth}\raggedright
Sample size control group\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.43\columnwidth}\raggedright
exponential of the normal distribution with a mean of 5 and variance of 0.3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.37\columnwidth}\raggedright
Ratio treatment:control group\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.43\columnwidth}\raggedright
1:1\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.37\columnwidth}\raggedright
Probability of event in control group\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.43\columnwidth}\raggedright
sampled from \enquote{unif(0.3, 0.7)}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{publication-bias}{%
\subsubsection{Publication bias}\label{publication-bias}}

Five different levels of publication bias were implemented: (i) No publication bias, (ii) moderate p-value based publication bias, (iii) severe p-value based publication bias, (iv) moderate effect-size based publication bias as well as (v) severe effect-size based publication bias.
Details regarding the implementation of each of these levels was obtained from the technical report (p.15, p.~20). The original article only mentions that funnel plot asymmetry was \emph{\enquote{{[}\ldots{]} induces in 2 ways. First, it was induced on the basis of the value associated with a study's effect size (the larger the P value the more likely that study was excluded from the meta-analysis).{[}\ldots{]} publication bias was also induced on the basis of study effect size with the most extreme negative effect sizes were excluded from the meta-analysis.}} (p.677)

For p-value based publication bias studies are censored as a result of the one-sided p-value associated with the effect estimate of interest. The p-value based selection probabilities is given in the following table which was taken from the technical report (table 2, report p.~15).

\begin{longtable}[]{@{}ccc@{}}
\toprule
Severity of publication bias & p-value & Selection Probability\tabularnewline
\midrule
\endhead
Moderate & \textless0.05 & 1\tabularnewline
& 0.05 - 0.2 & 0.75\tabularnewline
& 0.2-0.5 & 0.5\tabularnewline
& \textgreater0.5 & 0.25\tabularnewline
Severe & \textless0.05 & 1\tabularnewline
& 0.05-0.2 & 0.75\tabularnewline
& \textgreater0.2 & 0.25\tabularnewline
\bottomrule
\end{longtable}

For publication bias induced by effect size, a given percentage of studies with the most extreme effect estimates of effect are censored. For moderate publication bias this percentage corresponds to 14\% and for severe publication bias 40\% of studies.

Primary studies are generated following either a true or a random effects model depending on the presence of between-study heterogeneity in a given scenario.

\hypertarget{true-effect}{%
\subsubsection{True effect}\label{true-effect}}

Fixed effects model is given by
\(y_i=\theta + \epsilon_i\)
where \(\theta\) is the true underlying effect lnOR

Random effects model
\(y_i = \theta_i + \epsilon_i\)
with \(\theta_i~ N(\mu,\tau^2)\)
where \(\theta_i\) is the true effect in study \(i\)
\(\mu\) true underlying effect lnOR
\(\tau^2\) is the between-study variance

\hypertarget{between-study-heterogeneity}{%
\subsubsection{Between Study Heterogeneity}\label{between-study-heterogeneity}}

\emph{\enquote{{[}B{]}etween-study variance is defined to be 20\%, 150, and 500\% of the average within-study variance for studies from the corresponding simulations.
This compares with specifications of \(I^2\), describing the percentage of total variation across studies that is due to between-study heterogeneity rather than chance (ref 25). Here 20\%, 150\% and 500 \% of the within-study variation corresponds to an \(I^2\) of 16.7\%, 60\% and 83\% respectively.}} (technical report p.~12)

\hypertarget{size-of-control-group}{%
\subsubsection{Size of control group}\label{size-of-control-group}}

The number of participants in the control group of a given single study is sampled from the exponential of a normal distribution with a mean of 5 and a variance of 0.3 (article p.~677).
The technical report gives \(N(5, 0.3)\) as the distribution from which the number of control groups within each primary study is taken (report p.15). As this does not make much sense we interpreted it as a typo and followed the information from the original article.

\hypertarget{repetitions}{%
\subsubsection{Repetitions}\label{repetitions}}

Each of the 400 unique scenarios were repeated 1000 times (original article page 677).

\hypertarget{data-generating-process}{%
\subsubsection{Data generating process}\label{data-generating-process}}

Figure 1 provides a flow chart with an overview of the data generating process.

\begin{figure}
\centering
\includegraphics[width=6.14583in,height=\textheight]{../figures/flow_chart.png}
\caption{Flow chart of data generating mechanism}
\end{figure}

Data generation can be summarized with the following pseudo code:
\FloatBarrier
\texttt{For 1000 repetitions of each of 400 unique scenarios:}

\begin{itemize}[leftmargin=*] 
    \item[--] \texttt{Set unique seed based on scenario id and number of repetition.}
    \item[--] \texttt{Simulate an unbiased study set based on the control group event probability.}
    \item[--] \texttt{ While number of selected studies < number of required studies for given scenario:}
    \begin{itemize}
      \item[$\ast$] \texttt{Sample an event probability for the control group from the given distribution.}
      \item[$\ast$] \texttt{Sample a sample size from the given distribution.}
      \item[$\ast$] \texttt{Compute the remaining study characteristics based on these random elements.}
      \item[$\ast$] \texttt{Determine selection indicator based on publication bias mechanism of current scenario.}
    \end{itemize}
    \item[--] \texttt{If heterogeneity of present scenario is > 1: If heterogeneity of present scenario is > 1:}
    \begin{itemize}
      \item[$\ast$] \texttt{Determine original between-study variability \& resample from corresponding random effects model.}
    \end{itemize}
    \item[--] \texttt{Apply publication bias.}
\end{itemize}

\hypertarget{compared-methods}{%
\subsection{Compared Methods}\label{compared-methods}}

The study compares two regression tests for the detection of publication bias in meta-analyses.
The first Egger's regression test (Egger, Smith, Schneider, \& Minder, 1997) regresses the standardized effect estimate on a measure of precision (see equation 1).
The second (referred to as "alternative regression test in the original article) is a variation of Macaskill's test (Macaskill, Walter, \& Irwig, 2001) and regresses the effect size on the inverse of the total sample size (see equation 2).
We refer to this test as Peters' regression test in the present report.

\hypertarget{eggers-regression-test}{%
\subsubsection{Egger's regression test}\label{eggers-regression-test}}

\(\frac{y_i}{se_i}= \beta + \frac{\alpha}{se_i}+\epsilon_i\) which is equivalent to
\(y_i = \alpha +\beta \cdot se_i +\epsilon_i \cdot se_i\) weighted by \(\frac{1}{se_i^2}\)
where \(y_i\) is the lnOR from study i and \(se_i\) is the standard error of \(y_i\)
(report p.~22)

\hypertarget{peters-regression-test}{%
\subsubsection{Peters' regression test}\label{peters-regression-test}}

\(y_i = \alpha +\frac{\beta}{size_i} + \epsilon_i\) weighted by \((\frac{1}{A+B}+\frac{1}{C+D})^{-1}\)
(report p.23)

\hypertarget{performance-measures}{%
\subsection{Performance measures}\label{performance-measures}}

The original study compares the performance of the two regression tests on the basis of type I error rates and power.
The type 1 error rate (proportion of false positives) is defined as statistical significance specified from a 2-tailed test at \(p<.10\) (article p.~678).

\hypertarget{technical-implementation}{%
\subsection{Technical implementation}\label{technical-implementation}}

While the original simulation study was carried out in STATA 8.2 our replication was implemented
using the R programming environment (details regarding software versions can be obtained from the section Reproducibility Information).
The corresponding R code can be obtained from \url{https://github.com/replisims/peters-2016}.

\hypertarget{replicator-degrees-of-freedom}{%
\section{Replicator degrees of freedom}\label{replicator-degrees-of-freedom}}

The following table provides an overview of replicator degrees of freedom,
i.e.~decisions that had to be made by the replicators because of insufficient or contradicting information.
Issues were resolved by discussion among the replicators.
Decisions were based on what the replicators perceived to be the most likely implementation with likeliness estimated by common practice and/or guideline recommendations.
Wherever feasible multiple interpretations where implemented.

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.33\columnwidth}\raggedright
Issue\strut
\end{minipage} & \begin{minipage}[b]{0.33\columnwidth}\raggedright
Replicator decision\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Justification\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.33\columnwidth}\raggedright
Dealing with empty cells\strut
\end{minipage} & \begin{minipage}[t]{0.33\columnwidth}\raggedright
add 0.5 to every empty cell\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Common practice\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.33\columnwidth}\raggedright
Which set to compute average within-study-variance on\strut
\end{minipage} & \begin{minipage}[t]{0.33\columnwidth}\raggedright
largest number of studies generated before application of publication bias\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Most accurate correspondence to intended \(I^2\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.33\columnwidth}\raggedright
Data dependence\strut
\end{minipage} & \begin{minipage}[t]{0.33\columnwidth}\raggedright
each scenario is implemented in independently generated data\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Best practice (Burton, Altman, Royston, \& Holder, 2006)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.33\columnwidth}\raggedright
Fixed probability of event in control-group for all studies in one MA\strut
\end{minipage} & \begin{minipage}[t]{0.33\columnwidth}\raggedright
Probability of event in CG assumed as fixed\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
All replicators tended towards that interpretation\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.33\columnwidth}\raggedright
Exact scenario depicted in results\strut
\end{minipage} & \begin{minipage}[t]{0.33\columnwidth}\raggedright
Present multiple result subsetting\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Easy to implement alternative interpretations\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{empty-cells}{%
\subsection{Empty cells}\label{empty-cells}}

In the simulation of individual studies it is possible (albeit unlikely) for either the exposed group or the control group to not have any events (or no non-events).
This would make it impossible to compute the necessary parameters to continue the simulation.
Neither the original article nor the technical report provide any information whether such a case ever occurred and if so how it was dealt with.
We implemented the replication such that 0.5 is added to empty cells.

\hypertarget{simulation-of-between-study-heterogeneity}{%
\subsection{Simulation of between-study heterogeneity}\label{simulation-of-between-study-heterogeneity}}

The between-study heterogeneity parameter was calculated as a percentage of the average within-study variance estimate. From the fixed- effects model, the average within study variance was calculated and between-study heterogeneity was then defined to be 20\%, 150\% and 500\% of the within-study estimate.

It is unclear from which fixed-effects model the average within study variance was calculated (e.g.~what was the number of studies).
We interpreted this passage to refer to the fixed-effects model with the same parameter constellation (i.e.~the same OR and number of studies).
The random effects model was then redrawn after the average within-study variance was obtained.
It is furthermore unclear whether the average within-study variance was obtained before or after the application of publication bias.
In our replication we assumed it was before.

\hypertarget{publication-bias-based-on-effect-size}{%
\subsection{Publication bias based on effect size}\label{publication-bias-based-on-effect-size}}

The technical report describes the effect size based publication bias as follows:
\emph{\enquote{either 14\% or 40 \% of the most extreme studies showing a negative effect of the exposure (i.e.~OR \textless1) were censored such that the final number of studies in a meta -analysis was still 6, 16, 30, or 90 i.e.~for the 6 studies 10 haven been generated and 4 studies with the most extreme negative estimates have been censored}} The article similarly states \emph{\enquote{Studies with the most extreme negative effect sizes were excluded from the meta-analysis}} (p.677).

These statements are contradictory.
On the one hand it is suggested, that extreme studies with a negative effect of the exposure should be censored.
On the other hand it suggests to censor either 14\% or 40\% of studies.
Especially with large effect sized (e.g.~an OR of 5) it is highly unlikely to find 40\% of studies with a negative effect of the exposure.
We hence ignored the \enquote{negative effect} aspect and interpreted the authors' intention to be the exclusion of 14\% and 40\% of studies irrespective of the sign of the effect.

\hypertarget{data-dependence}{%
\subsection{Data dependence}\label{data-dependence}}

The number of studies in the meta-analysis is one of the simulation parameters.
As in every simulation study with sample size as one of the varied parameters the question arises whether the samples are dependent (i.e.~smaller samples being subsamples of larger samples) or independent (i.e.~each scenario independently sampled).
We could not find information regarding this in neither the original article nor the technical report.
We hence implemented each scenario as an independent sampling which is in line with current best practice recommendations (Burton et al., 2006).

\hypertarget{exact-scenario-depicted-in-results}{%
\subsection{Exact scenario depicted in results}\label{exact-scenario-depicted-in-results}}

The results are stratified by heterogeneity and method of inducing publication bias.
The plots are labeled with \emph{\enquote{publication bias induced by p-value}} and \emph{\enquote{publication bias induced by effect size}} correspondingly.
This suggests that results were collapsed over the severity of bias.
However, the following quote makes it seem like the results might only be depicted for severe bias:
\emph{"Power to detect \enquote{moderate} publication bias is lower than that to detect \enquote{severe} publication bias for all models. However, the same general trend in power is seen for \enquote{moderate} publication bias as the level of between-study heterogeneity increases, as it is for severe publication bias (results not shown).}
It is unclear whether \emph{\enquote{(results not shown)}} refers to the entirety of this passage (i.e.~the comparison of moderate vs severe bias is not shown) or whether it means to imply that all results depicted pertain to severe publication bias.
An additional passage suggests that indeed only severe publication bias might be plotted: \emph{\enquote{Model 4c has relatively good power to detect severe publication bias when there is no between-study heterogeneity compared to the other models, regardless of how publication bias is induced (Figures 10 and 11)}} (p.31-32 technical report). The article does not make a distinction between moderate and severe publication bias.
We resolve this problem by presenting figures for severe publication bias which seems the most likely choice based on the quotes provided above.
Additional figures for both collapsed publication bias as well as moderate publication bias are presented in the Appendix.

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{simulation-descriptives}{%
\subsection{Simulation descriptives}\label{simulation-descriptives}}

The technical report presents a figure showing the mean number of studies generated to obtain the number of studies required under \enquote{moderate} and \enquote{severe} bias (figure 2, p.17)
This closely corresponds to the numbers found in the replication.

\begin{figure}
\includegraphics[width=400pt]{../figures/studies_generated} \caption{Mean numbers of studies generated to obtain the number of studies required under 'moderate' and 'severe' bias}\label{fig:unnamed-chunk-1}
\end{figure}

\begin{figure}
\includegraphics[width=400pt]{../data/figure_2} \caption{Corresponding figure from the technical report}\label{fig:unnamed-chunk-2}
\end{figure}

As detailed above the exact procedure to simulate the heterogeneity was not sufficiently described in neither the article nor the technical report. The following figure shows the intended \(I^2\) compared to the observed \(I^2\) for a given meta-analysis both before as well as after the application of publication bias.

\begin{figure}
 \includegraphics[width=400pt]{../figures/i_squared_unbiased} \caption{Intended vs observed $I^2$ before publication bias}\label{fig:unnamed-chunk-3}
 \end{figure}

\begin{figure}
\includegraphics[width=400pt]{../figures/i_squared_biased} \caption{Intended vs observed $I^2$ after publication bias}\label{fig:unnamed-chunk-4}
\end{figure}

\hypertarget{replication-of-result-figures}{%
\subsection{Replication of result figures}\label{replication-of-result-figures}}

The following table provides an overview of figures related to central outcomes of the original study.

Overview of result figures in the original article and the technical report

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.30\columnwidth}\raggedright
Performance measure\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\raggedright
Test\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\raggedright
Scenario\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.30\columnwidth}\raggedright
Type I error rate\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Egger's regression test\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
all\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
Type I error rate\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Peter's regression test\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
no heterogeneity\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
Type I error rate\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Peter's regression test\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
500\% heterogeneity\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
Power\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Both\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
(severe ?) publication bias induced by effect size, no heterogeneity\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
Power\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Both\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
(severe ?) publication bias induced by p-value, no heterogeneity\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
Power\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Both\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
(severe ?) publication bias induced by p-value, OR 1,1.5 \& 5, all heterogeneity levels\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
Power\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Both\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
(severe?) publication bias induced by effect size, 500\% heterogeneity\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
Power\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Both\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
(severe?) publication bias induced by p-value, 500\% heterogeneity\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{type-1-error-rate}{%
\subsubsection{Type 1 error rate}\label{type-1-error-rate}}

The general trends regarding type one error rates of Egger's regression test and Peters' regression test can be regarded as replicated. However, a few noteworthy deviations from the original results emerged. While the type one error rate of Egger's test for an OR of one seemed to correspond to 10\% across differing degrees of heterogeneity, our results suggest that the type one error rate increases with increasing heterogeneity. A similar trend can be observed for an OR of 1.5. Comparing our results to figure 9 of the technical report where results are depicted for all OR it becomes evident that while similar the results differ in magnitude. Due to the low quality of the figure it is not possible to further specify these differences as the different lines cannot be matched to the corresponding ORs.

\begin{figure}
\includegraphics[width=400pt]{../figures/type_1_error} \caption{Type I error rate}\label{fig:unnamed-chunk-5}
\end{figure}

\begin{figure}
\includegraphics[width=400pt]{../data/type_1_error} \caption{Corresponding figure from the original article}\label{fig:unnamed-chunk-6}
\end{figure}

\hypertarget{power}{%
\subsubsection{Power}\label{power}}

The results pertaining to the power to detect severe publication bias induced by p-value seen to perfectly align regarding Peters' test. For Eggert's test the comparison is similar as with the type one error rate. Overall trends and magnitude is highly comparable with noteworthy exceptions. Again the trends for an OR of one deviate from the original study.
While the original study reports low power with no visible trend of increasing heterogeneity our results suggest that for OR close to 1 power increases with increasing heterogeneity.
More differences are visible when comparing our results to the figures from the technical report where it is evident that Peters' test exhibits some power for more than one OR while our results suggest that an OR of 1.5 was the only scenario with power substantially above the 10\% level.
There seem to be further discrepancies regarding the magnitude which again cannot be further quantified due to the lack of discrimination of different conditions in the original plots.

\begin{figure}
\includegraphics[width=400pt]{../figures/power_p_severe} \caption{Power to detect severe publication bias induced by p-value}\label{fig:unnamed-chunk-7}
\end{figure}
\begin{figure}
\includegraphics[width=400pt]{../data/power} \caption{Corresponding figure from the original article}\label{fig:unnamed-chunk-8}
\end{figure}

\hypertarget{replication-of-results-presented-in-text-form}{%
\subsection{Replication of results presented in text form}\label{replication-of-results-presented-in-text-form}}

\emph{\enquote{However, in Model 4c {[}which corresponds to the alternative test{]} we have a test that is superior to Egger's test in terms of expected type I error, but which also has good power to detect publication bias (equal to that of Egger's test), regardless of the amount of between-study heterogeneity.}} (report p.~46)

The superiority in terms of type one error rates can be clearly seen in our replication.
While Peters and colleagues do not specify their definition of \enquote{equal},
the power of Peter's test by no means seems equal to that of Egger's regression test.

\emph{\enquote{When there is little between-study heterogeneity, the alternative regression test and Egger's regression test appear to have moderate power to detect asymmetry when it is induced on the basis of P value (Figure 3) and high power when asymmetry is induced on the magnitude of the effect (data not shown).}} (article page 679)

While the authors do not define their definition of \enquote{moderate power} and \enquote{high power} we would not use these attributes to describe the results of our replication,
at least not in respect to Peter's test.
The wording furthermore seems to imply that the power of both tests is of a comparable magnitude which clearly does not seem to be the case in our replication.
Only for conditions of severe publication bias induced by effect size do claims of substantial power of Peters' test hold (see figure 9 in the appendix).

\FloatBarrier

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

\hypertarget{replicability}{%
\subsection{Replicability}\label{replicability}}

The original JAMA article is merely five pages long (including figures and references).
Consequently the article repeatedly refers to the technical report for details.
A total of 10 references to the technical report illustrate that replication merely based on the article would not have been feasible.
Crucial implementation details such as details about how publication bias was induced are missing from the published manuscript.
While unfortunately not available in the public domain we were able to obtain the technical report from the corresponding institution.
Fourteen years after publication this is commendable on parts of the department.
The technical report, which comprises 57 pages, does contain sufficient information for a replication.
A few details were, however, described in insufficient detail or using language that leaves room for interpretation on the part of the replicators.

\hypertarget{replicator-degrees-of-freedom-1}{%
\subsection{Replicator degrees of freedom}\label{replicator-degrees-of-freedom-1}}

The information that we found to be ambiguous or insufficient has to be interpreted from our unique perspective.
Other researchers with a different background (i.e.~different expertise, different language context, different point in history) might have encountered other uncertainties.
Furthermore, the fact that we found a certain aspect to be \enquote{clear} does not ensure correctness of our interpretation neither does finding something unclear automatically imply that our implementation was wrong.
Most replicator degrees of freedom concern the data generation.
Only one uncertainty is related to the scenarios the result presentation was based on.
The latter can easily be addressed by presenting the results in a multitude of ways.
Variation in the data generation is more complex to address.
In addition to the complexity of implementing several different interpretations (and their combinations) each full simulation run takes considerable computational resources.
The present simulation was comparably \enquote{cheap} with about eight hours of computation time.
The present replication hence only includes our \enquote{best guess} of what might have been the original authors intentions.

\hypertarget{equivalence-of-results}{%
\subsection{Equivalence of results}\label{equivalence-of-results}}

The mean number of studies generated per scenario seems to match that of the original study (compare figure X of this report and figure 2 of the technical report).
This indicates that we were able to replicate the data generation based on the p-value based publications bias.
Overall results regarding power and type one error roughly matched the original article in magnitude and trends.
Due to the above mentioned imprecisions regarding the bias type displayed in certain result figures it is hard to tell which figures should correspond to each other. Minor discrepancies might also be based on the simulation of heterogeneity which was somewhat vaguely described.

\hypertarget{acknowledgments}{%
\section{Acknowledgments}\label{acknowledgments}}

\newpage
\FloatBarrier

\hypertarget{references}{%
\section{References}\label{references}}

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-burton_design_2006}{}%
Burton, A., Altman, D. G., Royston, P., \& Holder, R. L. (2006). The design of simulation studies in medical statistics. \emph{Statistics in Medicine}, \emph{25}(24), 4279--4292. \url{https://doi.org/10.1002/sim.2673}

\leavevmode\hypertarget{ref-egger_bias_1997}{}%
Egger, M., Smith, G. D., Schneider, M., \& Minder, C. (1997). Bias in meta-analysis detected by a simple, graphical test. \emph{BMJ}, \emph{315}(7109), 629--634. \url{https://doi.org/10.1136/bmj.315.7109.629}

\leavevmode\hypertarget{ref-macaskill_comparison_2001}{}%
Macaskill, P., Walter, S. D., \& Irwig, L. (2001). A comparison of methods to detect publication bias in meta-analysis. \emph{Statistics in Medicine}, \emph{20}(4), 641--654. \url{https://doi.org/10.1002/sim.698}

\leavevmode\hypertarget{ref-peters_performance_2005}{}%
Peters, J. L., Sutton, A. J., Jones, D. R., Abrams, K. R., \& Rushton, L. (2005). \emph{Performance of tests and adjustments for publication bias in the presence of heterogeneity} (Technical Report No. 05-01) (pp. 1--57). Leicester: Department of Health Sciences, University of Leicester.

\leavevmode\hypertarget{ref-peters_comparison_2006}{}%
Peters, J. L., Sutton, A. J., Jones, D. R., Abrams, K. R., \& Rushton, L. (2006). Comparison of Two Methods to Detect Publication Bias in Meta-analysis. \emph{JAMA}, \emph{295}(6), 676--678. \url{https://doi.org/10.1001/jama.295.6.676}

\leavevmode\hypertarget{ref-rougier_sustainable_2017-1}{}%
Rougier, N. P., Hinsen, K., Alexandre, F., Arildsen, T., Barba, L. A., Benureau, F. C. Y., \ldots{} Zito, T. (2017). Sustainable computational science: The ReScience initiative. \emph{PeerJ Computer Science}, \emph{3}, e142. \url{https://doi.org/10.7717/peerj-cs.142}

\FloatBarrier
\newpage

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{additional-result-plots}{%
\subsection{Additional result plots}\label{additional-result-plots}}

\begin{figure}
\includegraphics[width=400pt]{../figures/power_p_moderate} \caption{Power to detect moderate publication bias induced by p-value}\label{fig:unnamed-chunk-9}
\end{figure}

\begin{figure}
\includegraphics[width=400pt]{../figures/power_es_severe} \caption{Power to detect severe publication bias induced by effect size}\label{fig:unnamed-chunk-10}
\end{figure}

\begin{figure}
\includegraphics[width=400pt]{../figures/power_es_moderate} \caption{Power to detect moderate publication bias induced by effect}\label{fig:unnamed-chunk-11}
\end{figure}
\FloatBarrier

\hypertarget{code-organization}{%
\subsection{Code organization}\label{code-organization}}

The code and the files associated are organized in the form of a research compendium
which can be found in the following git repository \texttt{https://github.com/replisims/peters-2016}

\begin{minipage}{\linewidth}
\begin{verbatim}
peters2006
├── analysis
│   ├── 01_data_generation.R
│   ├── 02_publication_bias_testing.R
│   ├── 03_performance_plots.R
│   ├── 05_primary_study_selection_plot.R
│   ├── 06_heterogeneity_plots.R
│   ├── data
│   ├── figures
│   ├── nested_loop_plot.R
│   ├── report
│   └── shiny
│       └── shiny.R
├── data
│   └── scenarios.rda
├── DESCRIPTION
├── man
├── NAMESPACE
├── peters2006.Rproj
├── R
│   ├── data_generation_functions.R
│   ├── data.R
│   ├── plot_error_rate.R
│   ├── plot_helper.R
│   ├── plot_i_squared.R
│   ├── run_sim.R
│   ├── scenarios.R
│   └── test_functions.R
└── README.md
\end{verbatim}
\end{minipage}

\begin{itemize}
\tightlist
\item
  \texttt{data}: contains the package data in this case a data frame with the original simulation scenarios
\item
  \texttt{man}: contains the documentation for all package functions
\item
  \texttt{analysis}: contains code to run the simulation

  \begin{itemize}
  \tightlist
  \item
    \texttt{01\_data\_generation.R}
    run the simulation with the original simulation parameters
  \item
    \texttt{02\_publication\_bias\_testing.R}
    apply Egger's and Peters' regression test to generated data
  \item
    \texttt{03\_performance\ plots} obtain plots for type 1 error rate and power
  \item
    \texttt{04\_primary\_study\_selection\_plot} plot the number of primary studies generated before publication bias
  \item
    \texttt{05\_heterogeneity\_plots\ plot} intended vs observed heterogeneity under various publication bias scenarios
  \end{itemize}
\end{itemize}

\hypertarget{reproducibility-information}{%
\subsubsection{Reproducibility Information}\label{reproducibility-information}}

This report was last updated on 2020-09-18 00:03:25.
The simulation replication was conducted using the following computational environment and dependencies:
\FloatBarrier

\begin{verbatim}
#> - Session info ---------------------------------------------------------------
#>  setting  value                       
#>  version  R version 3.6.3 (2020-02-29)
#>  os       Windows 10 x64              
#>  system   x86_64, mingw32             
#>  ui       RTerm                       
#>  language (EN)                        
#>  collate  English_United States.1252  
#>  ctype    English_United States.1252  
#>  tz       Europe/Berlin               
#>  date     2020-09-18                  
#> 
#> - Packages -------------------------------------------------------------------
#>  package     * version    date       lib source                      
#>  assertthat    0.2.1      2019-03-21 [1] CRAN (R 3.6.3)              
#>  backports     1.1.6      2020-04-05 [1] CRAN (R 3.6.3)              
#>  bookdown      0.20       2020-06-23 [1] CRAN (R 3.6.3)              
#>  callr         3.4.4      2020-09-07 [1] CRAN (R 3.6.3)              
#>  cli           2.0.2      2020-02-28 [1] CRAN (R 3.6.3)              
#>  crayon        1.3.4      2017-09-16 [1] CRAN (R 3.6.3)              
#>  desc          1.2.0      2018-05-01 [1] CRAN (R 3.6.3)              
#>  devtools      2.3.1      2020-07-21 [1] CRAN (R 3.6.3)              
#>  digest        0.6.25     2020-02-23 [1] CRAN (R 3.6.3)              
#>  ellipsis      0.3.1      2020-05-15 [1] CRAN (R 3.6.3)              
#>  evaluate      0.14       2019-05-28 [1] CRAN (R 3.6.3)              
#>  fansi         0.4.1      2020-01-08 [1] CRAN (R 3.6.3)              
#>  fs            1.4.1      2020-04-04 [1] CRAN (R 3.6.3)              
#>  glue          1.4.1      2020-05-13 [1] CRAN (R 3.6.3)              
#>  htmltools     0.5.0      2020-06-16 [1] CRAN (R 3.6.3)              
#>  knitr         1.29       2020-06-23 [1] CRAN (R 3.6.3)              
#>  magrittr      1.5        2014-11-22 [1] CRAN (R 3.6.3)              
#>  memoise       1.1.0      2017-04-21 [1] CRAN (R 3.6.3)              
#>  papaja      * 0.1.0.9997 2020-08-25 [1] Github (crsh/papaja@0457653)
#>  pkgbuild      1.1.0      2020-07-13 [1] CRAN (R 3.6.3)              
#>  pkgload       1.0.2      2018-10-29 [1] CRAN (R 3.6.3)              
#>  prettyunits   1.1.1      2020-01-24 [1] CRAN (R 3.6.3)              
#>  processx      3.4.2      2020-02-09 [1] CRAN (R 3.6.3)              
#>  ps            1.3.2      2020-02-13 [1] CRAN (R 3.6.3)              
#>  R6            2.4.1      2019-11-12 [1] CRAN (R 3.6.3)              
#>  remotes       2.2.0      2020-07-21 [1] CRAN (R 3.6.3)              
#>  rlang         0.4.6      2020-05-02 [1] CRAN (R 3.6.3)              
#>  rmarkdown     2.3        2020-06-18 [1] CRAN (R 3.6.3)              
#>  rprojroot     1.3-2      2018-01-03 [1] CRAN (R 3.6.3)              
#>  sessioninfo   1.1.1      2018-11-05 [1] CRAN (R 3.6.3)              
#>  stringi       1.4.6      2020-02-17 [1] CRAN (R 3.6.2)              
#>  stringr       1.4.0      2019-02-10 [1] CRAN (R 3.6.3)              
#>  testthat      2.3.2      2020-03-02 [1] CRAN (R 3.6.3)              
#>  usethis       1.6.1      2020-04-29 [1] CRAN (R 3.6.3)              
#>  withr         2.2.0      2020-04-20 [1] CRAN (R 3.6.3)              
#>  xfun          0.15       2020-06-21 [1] CRAN (R 3.6.3)              
#>  yaml          2.2.1      2020-02-01 [1] CRAN (R 3.6.2)              
#> 
#> [1] C:/Users/Anna/Documents/R/win-library/3.6
#> [2] C:/Program Files/R/R-3.6.3/library
\end{verbatim}

The current Git commit details are:

\begin{verbatim}
#> Local:    wip C:/Users/Anna/Dropbox/anna/projects/replisims/peters2006
#> Remote:   wip @ origin (https://github.com/replisims/peters-2016.git)
#> Head:     [33a7d64] 2020-09-17: Update
\end{verbatim}


\end{document}
